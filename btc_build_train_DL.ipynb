{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd04cb5ea3394bfdc6abf1cba6e6023a5136a123bd60d92a96eabaf849483bfdf79",
   "display_name": "Python 3.7.9 64-bit ('dev': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_nPCs = [10, 15, 20, 25, 30]\n",
    "takeprofit = 0.12\n",
    "stoploss = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) Load previously built datasets : we just need train sets and validation sets here\n",
    "trainset_final = pd.read_csv('./Data/Trainset_final_SL{}_TP{}_btc.csv'.format(stoploss, takeprofit))\n",
    "trainset = pd.read_csv('./Data/Trainset_SL{}_TP{}_btc.csv'.format(stoploss, takeprofit))\n",
    "\n",
    "validation_set_final = pd.read_csv('./Data/Validationset_final_SL{}_TP{}_btc.csv'.format(stoploss, takeprofit))\n",
    "validation_set = pd.read_csv('./Data/Validationset_SL{}_TP{}_btc.csv'.format(stoploss, takeprofit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for nPCs in list_nPCs:\n",
    "#     print(nPCs)\n",
    "#     X = trainset_final.iloc[:, :nPCs]\n",
    "#     y = trainset[\"result\"]\n",
    "\n",
    "#     # Build model and train it\n",
    "#     classifier = Sequential()\n",
    "\n",
    "#     dropout_fraction = 0.2\n",
    "\n",
    "#     #First Hidden Layer\n",
    "#     classifier.add(Dense(32, activation='relu', kernel_initializer='random_normal', input_dim=nPCs))\n",
    "#     classifier.add(Dropout(dropout_fraction))\n",
    "\n",
    "#     #Second, third and fourth  hidden Layers\n",
    "#     classifier.add(Dense(32, activation='relu', kernel_initializer='random_normal'))\n",
    "#     classifier.add(Dropout(dropout_fraction))\n",
    "\n",
    "#     classifier.add(Dense(16, activation='relu', kernel_initializer='random_normal'))\n",
    "#     classifier.add(Dropout(dropout_fraction))\n",
    "\n",
    "#     classifier.add(Dense(16, activation='relu', kernel_initializer='random_normal'))\n",
    "#     classifier.add(Dropout(dropout_fraction))\n",
    "\n",
    "#     #Output Layer\n",
    "#     classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "#     #Compiling the neural network\n",
    "#     classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "#     #Fitting the data to the training dataset\n",
    "#     classifier.fit(X,y, batch_size=50, epochs=75, verbose =1)\n",
    "\n",
    "#     pk.dump(classifier, open(\"./Models/DL_model_{}PC_SL{}_TP{}_btc.pkl\".format(nPCs, stoploss, takeprofit), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.6569 - accuracy: 0.7260\n",
      "Epoch 2/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.4840 - accuracy: 0.7326\n",
      "Epoch 3/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.4560 - accuracy: 0.7926\n",
      "Epoch 4/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.4319 - accuracy: 0.7968\n",
      "Epoch 5/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.4231 - accuracy: 0.8068\n",
      "Epoch 6/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.3825 - accuracy: 0.8135\n",
      "Epoch 7/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.3522 - accuracy: 0.8099\n",
      "Epoch 8/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.3607 - accuracy: 0.8489\n",
      "Epoch 9/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.3432 - accuracy: 0.8408\n",
      "Epoch 10/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.3327 - accuracy: 0.8427\n",
      "Epoch 11/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2809 - accuracy: 0.8876\n",
      "Epoch 12/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.2760 - accuracy: 0.8704\n",
      "Epoch 13/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2891 - accuracy: 0.8558\n",
      "Epoch 14/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.2981 - accuracy: 0.8778\n",
      "Epoch 15/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.2807 - accuracy: 0.8761\n",
      "Epoch 16/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.3312 - accuracy: 0.8385\n",
      "Epoch 17/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.2765 - accuracy: 0.8721\n",
      "Epoch 18/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.2384 - accuracy: 0.8784\n",
      "Epoch 19/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2430 - accuracy: 0.9080\n",
      "Epoch 20/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.3083 - accuracy: 0.8725\n",
      "Epoch 21/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2997 - accuracy: 0.8799\n",
      "Epoch 22/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.2538 - accuracy: 0.8915\n",
      "Epoch 23/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2767 - accuracy: 0.8846\n",
      "Epoch 24/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2418 - accuracy: 0.8883\n",
      "Epoch 25/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2959 - accuracy: 0.8802\n",
      "Epoch 26/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2428 - accuracy: 0.8812\n",
      "Epoch 27/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.2109 - accuracy: 0.9144\n",
      "Epoch 28/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2224 - accuracy: 0.9110\n",
      "Epoch 29/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1959 - accuracy: 0.9283\n",
      "Epoch 30/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.2234 - accuracy: 0.9185\n",
      "Epoch 31/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2190 - accuracy: 0.9039\n",
      "Epoch 32/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2144 - accuracy: 0.9137\n",
      "Epoch 33/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1889 - accuracy: 0.9170\n",
      "Epoch 34/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.2104 - accuracy: 0.8875\n",
      "Epoch 35/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1931 - accuracy: 0.9339\n",
      "Epoch 36/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2417 - accuracy: 0.9036\n",
      "Epoch 37/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1941 - accuracy: 0.9205\n",
      "Epoch 38/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.2085 - accuracy: 0.9188\n",
      "Epoch 39/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1948 - accuracy: 0.9044\n",
      "Epoch 40/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1811 - accuracy: 0.9111\n",
      "Epoch 41/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1944 - accuracy: 0.9283\n",
      "Epoch 42/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1581 - accuracy: 0.9367\n",
      "Epoch 43/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1876 - accuracy: 0.9191\n",
      "Epoch 44/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1752 - accuracy: 0.9455\n",
      "Epoch 45/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1751 - accuracy: 0.9264\n",
      "Epoch 46/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1741 - accuracy: 0.9342\n",
      "Epoch 47/75\n",
      "402/402 [==============================] - 0s 1ms/step - loss: 0.1712 - accuracy: 0.9002\n",
      "Epoch 48/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1117 - accuracy: 0.9711\n",
      "Epoch 49/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1813 - accuracy: 0.9230\n",
      "Epoch 50/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1700 - accuracy: 0.9434\n",
      "Epoch 51/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1741 - accuracy: 0.9268\n",
      "Epoch 52/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1037 - accuracy: 0.9628\n",
      "Epoch 53/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1167 - accuracy: 0.9598\n",
      "Epoch 54/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1330 - accuracy: 0.9413\n",
      "Epoch 55/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2048 - accuracy: 0.9461\n",
      "Epoch 56/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2212 - accuracy: 0.8967\n",
      "Epoch 57/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1751 - accuracy: 0.9204\n",
      "Epoch 58/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1481 - accuracy: 0.9452\n",
      "Epoch 59/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1213 - accuracy: 0.9499\n",
      "Epoch 60/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1475 - accuracy: 0.9450\n",
      "Epoch 61/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1315 - accuracy: 0.9440\n",
      "Epoch 62/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1050 - accuracy: 0.9470\n",
      "Epoch 63/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.2713 - accuracy: 0.8903\n",
      "Epoch 64/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1567 - accuracy: 0.9459\n",
      "Epoch 65/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1566 - accuracy: 0.9410\n",
      "Epoch 66/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1906 - accuracy: 0.9407\n",
      "Epoch 67/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1432 - accuracy: 0.9528\n",
      "Epoch 68/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1802 - accuracy: 0.9186\n",
      "Epoch 69/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1470 - accuracy: 0.9308\n",
      "Epoch 70/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1639 - accuracy: 0.9336\n",
      "Epoch 71/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1768 - accuracy: 0.9194\n",
      "Epoch 72/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1524 - accuracy: 0.9338\n",
      "Epoch 73/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1628 - accuracy: 0.9286\n",
      "Epoch 74/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1380 - accuracy: 0.9268\n",
      "Epoch 75/75\n",
      "402/402 [==============================] - 0s 1ms/step - loss: 0.1271 - accuracy: 0.9491\n"
     ]
    }
   ],
   "source": [
    "# 10 nPCs model\n",
    "X = trainset_final.iloc[:, :10]\n",
    "y = trainset[\"result\"]\n",
    "\n",
    "# Build model and train it\n",
    "classifier = Sequential()\n",
    "\n",
    "dropout_fraction = 0.2\n",
    "\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(32, activation='relu', kernel_initializer='random_normal', input_dim=10))\n",
    "classifier.add(Dropout(dropout_fraction))\n",
    "\n",
    "#Second, third and fourth  hidden Layers\n",
    "classifier.add(Dense(32, activation='relu', kernel_initializer='random_normal'))\n",
    "classifier.add(Dropout(dropout_fraction))\n",
    "\n",
    "classifier.add(Dense(16, activation='relu', kernel_initializer='random_normal'))\n",
    "classifier.add(Dropout(dropout_fraction))\n",
    "\n",
    "classifier.add(Dense(16, activation='relu', kernel_initializer='random_normal'))\n",
    "classifier.add(Dropout(dropout_fraction))\n",
    "\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "#Fitting the data to the training dataset\n",
    "model = classifier.fit(X,y, batch_size=1, epochs=75, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_json = classifier.to_json()\n",
    "\n",
    "file_path = Path(\"./Models/DL_model_10PC.json\")\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json_file.write(class_json)\n",
    "\n",
    "file_path = \"./Models/DL_model_10PC.h5\"\n",
    "classifier.save_weights(\"./Models/DL_model_10PC.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies, nPCs_list = [], []\n",
    "file_path = Path(\"./Models/DL_model_10PC.json\")\n",
    "with open(file_path, \"r\") as json_file:\n",
    "    model_json = json_file.read()\n",
    "loaded_model = model_from_json(model_json)\n",
    "\n",
    "file_path = Path(\"./Models/DL_model_10PC.h5\")\n",
    "loaded_model.load_weights(file_path)\n",
    "# Compute predictions on testset\n",
    "preds = (loaded_model.predict(validation_set_final.iloc[:, :10]) > 0.5)*1\n",
    "\n",
    "# Assess accuracy on Bullish predictions only (because we will only perform Bullish trades IRL) : we prioritize selectivity\n",
    "validation_set1 = validation_set[preds == 1].copy()\n",
    "accuracies.append(np.mean(preds == list(validation_set1['result'])))\n",
    "nPCs_list.append(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.6477 - accuracy: 0.6982\n",
      "Epoch 2/75\n",
      "402/402 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7488\n",
      "Epoch 3/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.4169 - accuracy: 0.8279\n",
      "Epoch 4/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.4242 - accuracy: 0.8114\n",
      "Epoch 5/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.4412 - accuracy: 0.8338\n",
      "Epoch 6/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.3583 - accuracy: 0.8566\n",
      "Epoch 7/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.3629 - accuracy: 0.8588\n",
      "Epoch 8/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.3640 - accuracy: 0.8465\n",
      "Epoch 9/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.3326 - accuracy: 0.8392\n",
      "Epoch 10/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.3289 - accuracy: 0.8714\n",
      "Epoch 11/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.2680 - accuracy: 0.8879\n",
      "Epoch 12/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.3107 - accuracy: 0.8666\n",
      "Epoch 13/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.3237 - accuracy: 0.8629\n",
      "Epoch 14/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.3538 - accuracy: 0.8743\n",
      "Epoch 15/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2647 - accuracy: 0.9024\n",
      "Epoch 16/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.2624 - accuracy: 0.8904\n",
      "Epoch 17/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.2603 - accuracy: 0.8941\n",
      "Epoch 18/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.2360 - accuracy: 0.8998\n",
      "Epoch 19/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.2659 - accuracy: 0.8923\n",
      "Epoch 20/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.2615 - accuracy: 0.9077\n",
      "Epoch 21/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2063 - accuracy: 0.9120\n",
      "Epoch 22/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1965 - accuracy: 0.9262\n",
      "Epoch 23/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.2625 - accuracy: 0.8833\n",
      "Epoch 24/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1933 - accuracy: 0.9112\n",
      "Epoch 25/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.2217 - accuracy: 0.9031\n",
      "Epoch 26/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1950 - accuracy: 0.9225\n",
      "Epoch 27/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1906 - accuracy: 0.9107\n",
      "Epoch 28/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.2360 - accuracy: 0.8893\n",
      "Epoch 29/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1505 - accuracy: 0.9413\n",
      "Epoch 30/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.2008 - accuracy: 0.9300\n",
      "Epoch 31/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1831 - accuracy: 0.9220\n",
      "Epoch 32/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1230 - accuracy: 0.9616\n",
      "Epoch 33/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1898 - accuracy: 0.9295\n",
      "Epoch 34/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1733 - accuracy: 0.9401\n",
      "Epoch 35/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1470 - accuracy: 0.9477\n",
      "Epoch 36/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1796 - accuracy: 0.9258\n",
      "Epoch 37/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1089 - accuracy: 0.9495\n",
      "Epoch 38/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2188 - accuracy: 0.8757\n",
      "Epoch 39/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1678 - accuracy: 0.9333\n",
      "Epoch 40/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1335 - accuracy: 0.9532\n",
      "Epoch 41/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1413 - accuracy: 0.9528\n",
      "Epoch 42/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1486 - accuracy: 0.9320\n",
      "Epoch 43/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1513 - accuracy: 0.9352\n",
      "Epoch 44/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1313 - accuracy: 0.9691\n",
      "Epoch 45/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1659 - accuracy: 0.9057\n",
      "Epoch 46/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1453 - accuracy: 0.9485\n",
      "Epoch 47/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1731 - accuracy: 0.9407\n",
      "Epoch 48/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1614 - accuracy: 0.9216\n",
      "Epoch 49/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1824 - accuracy: 0.9089\n",
      "Epoch 50/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1938 - accuracy: 0.9106\n",
      "Epoch 51/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1440 - accuracy: 0.9572\n",
      "Epoch 52/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0959 - accuracy: 0.9765\n",
      "Epoch 53/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1079 - accuracy: 0.9647\n",
      "Epoch 54/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1145 - accuracy: 0.9515\n",
      "Epoch 55/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.9523\n",
      "Epoch 56/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9711\n",
      "Epoch 57/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1415 - accuracy: 0.9740\n",
      "Epoch 58/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1800 - accuracy: 0.9352\n",
      "Epoch 59/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1370 - accuracy: 0.9554\n",
      "Epoch 60/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1672 - accuracy: 0.9366\n",
      "Epoch 61/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1317 - accuracy: 0.9637\n",
      "Epoch 62/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.0832 - accuracy: 0.9778\n",
      "Epoch 63/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0776 - accuracy: 0.9767\n",
      "Epoch 64/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.2566 - accuracy: 0.9078\n",
      "Epoch 65/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0798 - accuracy: 0.9824\n",
      "Epoch 66/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1021 - accuracy: 0.9611\n",
      "Epoch 67/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1556 - accuracy: 0.9326\n",
      "Epoch 68/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1559 - accuracy: 0.9504\n",
      "Epoch 69/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1212 - accuracy: 0.9512\n",
      "Epoch 70/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1265 - accuracy: 0.9494\n",
      "Epoch 71/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1113 - accuracy: 0.9570\n",
      "Epoch 72/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9476\n",
      "Epoch 73/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0948 - accuracy: 0.9702\n",
      "Epoch 74/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9622\n",
      "Epoch 75/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1270 - accuracy: 0.9520\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24626b8de48>"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# 15 nPCs model\n",
    "X = trainset_final.iloc[:, :15]\n",
    "y = trainset[\"result\"]\n",
    "\n",
    "# Build model and train it\n",
    "classifier = Sequential()\n",
    "\n",
    "dropout_fraction = 0.2\n",
    "\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(32, activation='relu', kernel_initializer='random_normal', input_dim=15))\n",
    "classifier.add(Dropout(dropout_fraction))\n",
    "\n",
    "#Second, third and fourth  hidden Layers\n",
    "classifier.add(Dense(32, activation='relu', kernel_initializer='random_normal'))\n",
    "classifier.add(Dropout(dropout_fraction))\n",
    "\n",
    "classifier.add(Dense(16, activation='relu', kernel_initializer='random_normal'))\n",
    "classifier.add(Dropout(dropout_fraction))\n",
    "\n",
    "classifier.add(Dense(16, activation='relu', kernel_initializer='random_normal'))\n",
    "classifier.add(Dropout(dropout_fraction))\n",
    "\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "#Fitting the data to the training dataset\n",
    "classifier.fit(X,y, batch_size=1, epochs=75, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_json = classifier.to_json()\n",
    "\n",
    "file_path = Path(\"./Models/DL_model_15PC.json\")\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json_file.write(class_json)\n",
    "\n",
    "file_path = \"./Models/DL_model_15PC.h5\"\n",
    "classifier.save_weights(\"./Models/DL_model_15PC.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(\"./Models/DL_model_15PC.json\")\n",
    "with open(file_path, \"r\") as json_file:\n",
    "    model_json = json_file.read()\n",
    "loaded_model = model_from_json(model_json)\n",
    "\n",
    "file_path = Path(\"./Models/DL_model_15PC.h5\")\n",
    "loaded_model.load_weights(file_path)\n",
    "# Compute predictions on testset\n",
    "preds = (loaded_model.predict(validation_set_final.iloc[:, :15]) > 0.5)*1\n",
    "\n",
    "# Assess accuracy on Bullish predictions only (because we will only perform Bullish trades IRL) : we prioritize selectivity\n",
    "validation_set1 = validation_set[preds == 1].copy()\n",
    "accuracies.append(np.mean(preds == list(validation_set1['result'])))\n",
    "nPCs_list.append(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.6597 - accuracy: 0.6523\n",
      "Epoch 2/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.4810 - accuracy: 0.7399\n",
      "Epoch 3/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.4085 - accuracy: 0.8137\n",
      "Epoch 4/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.3727 - accuracy: 0.8453\n",
      "Epoch 5/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.3086 - accuracy: 0.8801\n",
      "Epoch 6/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2337 - accuracy: 0.9099\n",
      "Epoch 7/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2055 - accuracy: 0.9287\n",
      "Epoch 8/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.2033 - accuracy: 0.9350\n",
      "Epoch 9/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1725 - accuracy: 0.9210\n",
      "Epoch 10/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1806 - accuracy: 0.9304\n",
      "Epoch 11/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1638 - accuracy: 0.9450\n",
      "Epoch 12/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1920 - accuracy: 0.9257\n",
      "Epoch 13/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1666 - accuracy: 0.9313\n",
      "Epoch 14/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1662 - accuracy: 0.9381\n",
      "Epoch 15/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1617 - accuracy: 0.9294\n",
      "Epoch 16/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.9352\n",
      "Epoch 17/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1616 - accuracy: 0.9502\n",
      "Epoch 18/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1770 - accuracy: 0.9467\n",
      "Epoch 19/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1207 - accuracy: 0.9493\n",
      "Epoch 20/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0903 - accuracy: 0.9644\n",
      "Epoch 21/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0886 - accuracy: 0.9682\n",
      "Epoch 22/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1432 - accuracy: 0.9463\n",
      "Epoch 23/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1083 - accuracy: 0.9542\n",
      "Epoch 24/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1089 - accuracy: 0.9603\n",
      "Epoch 25/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0888 - accuracy: 0.9609\n",
      "Epoch 26/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0861 - accuracy: 0.9663\n",
      "Epoch 27/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1194 - accuracy: 0.9668\n",
      "Epoch 28/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.9637\n",
      "Epoch 29/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1392 - accuracy: 0.9350\n",
      "Epoch 30/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.0776 - accuracy: 0.9628\n",
      "Epoch 31/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1121 - accuracy: 0.9601\n",
      "Epoch 32/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0925 - accuracy: 0.9638\n",
      "Epoch 33/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0931 - accuracy: 0.9556\n",
      "Epoch 34/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0553 - accuracy: 0.9820\n",
      "Epoch 35/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0465 - accuracy: 0.9910\n",
      "Epoch 36/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1040 - accuracy: 0.9683\n",
      "Epoch 37/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0420 - accuracy: 0.9806\n",
      "Epoch 38/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0370 - accuracy: 0.9862\n",
      "Epoch 39/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1151 - accuracy: 0.9582\n",
      "Epoch 40/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.0545 - accuracy: 0.9815\n",
      "Epoch 41/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0802 - accuracy: 0.9828\n",
      "Epoch 42/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0522 - accuracy: 0.9732\n",
      "Epoch 43/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0562 - accuracy: 0.9849\n",
      "Epoch 44/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.0392 - accuracy: 0.9875\n",
      "Epoch 45/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0956 - accuracy: 0.9631\n",
      "Epoch 46/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1312 - accuracy: 0.9618\n",
      "Epoch 47/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.0585 - accuracy: 0.9771\n",
      "Epoch 48/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0339 - accuracy: 0.9946\n",
      "Epoch 49/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0480 - accuracy: 0.9732\n",
      "Epoch 50/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1022 - accuracy: 0.9719\n",
      "Epoch 51/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0611 - accuracy: 0.9682\n",
      "Epoch 52/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0627 - accuracy: 0.9766\n",
      "Epoch 53/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0518 - accuracy: 0.9815\n",
      "Epoch 54/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1098 - accuracy: 0.9645\n",
      "Epoch 55/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.0429 - accuracy: 0.9858\n",
      "Epoch 56/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.1117 - accuracy: 0.9497\n",
      "Epoch 57/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0551 - accuracy: 0.9842\n",
      "Epoch 58/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0504 - accuracy: 0.9734\n",
      "Epoch 59/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0464 - accuracy: 0.9854\n",
      "Epoch 60/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0647 - accuracy: 0.9725\n",
      "Epoch 61/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0536 - accuracy: 0.9767\n",
      "Epoch 62/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0402 - accuracy: 0.9928\n",
      "Epoch 63/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0787 - accuracy: 0.9673\n",
      "Epoch 64/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0454 - accuracy: 0.9787\n",
      "Epoch 65/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0731 - accuracy: 0.9793\n",
      "Epoch 66/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0923 - accuracy: 0.9688\n",
      "Epoch 67/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0337 - accuracy: 0.9872\n",
      "Epoch 68/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0430 - accuracy: 0.9796\n",
      "Epoch 69/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0440 - accuracy: 0.9857\n",
      "Epoch 70/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0170 - accuracy: 0.9921\n",
      "Epoch 71/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0345 - accuracy: 0.9896\n",
      "Epoch 72/75\n",
      "402/402 [==============================] - 1s 1ms/step - loss: 0.0574 - accuracy: 0.9818\n",
      "Epoch 73/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.0433 - accuracy: 0.9792\n",
      "Epoch 74/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.0297 - accuracy: 0.9927\n",
      "Epoch 75/75\n",
      "402/402 [==============================] - 1s 2ms/step - loss: 0.1630 - accuracy: 0.9525\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24627026588>"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# 20 nPCs model\n",
    "X = trainset_final.iloc[:, :20]\n",
    "y = trainset[\"result\"]\n",
    "\n",
    "# Build model and train it\n",
    "classifier = Sequential()\n",
    "\n",
    "dropout_fraction = 0.2\n",
    "\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(32, activation='relu', kernel_initializer='random_normal', input_dim=20))\n",
    "classifier.add(Dropout(dropout_fraction))\n",
    "\n",
    "#Second, third and fourth  hidden Layers\n",
    "classifier.add(Dense(32, activation='relu', kernel_initializer='random_normal'))\n",
    "classifier.add(Dropout(dropout_fraction))\n",
    "\n",
    "classifier.add(Dense(16, activation='relu', kernel_initializer='random_normal'))\n",
    "classifier.add(Dropout(dropout_fraction))\n",
    "\n",
    "classifier.add(Dense(16, activation='relu', kernel_initializer='random_normal'))\n",
    "classifier.add(Dropout(dropout_fraction))\n",
    "\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "#Fitting the data to the training dataset\n",
    "classifier.fit(X,y, batch_size=1, epochs=75, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_json = classifier.to_json()\n",
    "\n",
    "file_path = Path(\"./Models/DL_model_20PC.json\")\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json_file.write(class_json)\n",
    "\n",
    "file_path = \"./Models/DL_model_20PC.h5\"\n",
    "classifier.save_weights(\"./Models/DL_model_20PC.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(\"./Models/DL_model_20PC.json\")\n",
    "with open(file_path, \"r\") as json_file:\n",
    "    model_json = json_file.read()\n",
    "loaded_model = model_from_json(model_json)\n",
    "\n",
    "file_path = Path(\"./Models/DL_model_20PC.h5\")\n",
    "loaded_model.load_weights(file_path)\n",
    "# Compute predictions on testset\n",
    "preds = (loaded_model.predict(validation_set_final.iloc[:, :20]) > 0.5)*1\n",
    "\n",
    "# Assess accuracy on Bullish predictions only (because we will only perform Bullish trades IRL) : we prioritize selectivity\n",
    "validation_set1 = validation_set[preds == 1].copy()\n",
    "accuracies.append(np.mean(preds == list(validation_set1['result'])))\n",
    "nPCs_list.append(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "recap = pd.DataFrame({'nPCs' : list(nPCs_list), 'Accuracy' : (list(accuracies))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   nPCs  Accuracy\n",
       "0    10  0.037037\n",
       "1    15  0.351852\n",
       "2    20  0.018519"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nPCs</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>0.037037</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15</td>\n      <td>0.351852</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20</td>\n      <td>0.018519</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}