{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python379jvsc74a57bd04cb5ea3394bfdc6abf1cba6e6023a5136a123bd60d92a96eabaf849483bfdf79",
   "display_name": "Python 3.7.9 64-bit ('dev': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_nPCs = [10, 15, 20, 25, 30]\n",
    "takeprofit = 0.12\n",
    "stoploss = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) Load previously built datasets : we just need train sets and validation sets here\n",
    "trainset_final = pd.read_csv('./Data/Trainset_final_SL{}_TP{}_btc.csv'.format(stoploss, takeprofit))\n",
    "trainset = pd.read_csv('./Data/Trainset_SL{}_TP{}_btc.csv'.format(stoploss, takeprofit))\n",
    "\n",
    "validation_set_final = pd.read_csv('./Data/Validationset_final_SL{}_TP{}_btc.csv'.format(stoploss, takeprofit))\n",
    "validation_set = pd.read_csv('./Data/Validationset_SL{}_TP{}_btc.csv'.format(stoploss, takeprofit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10\n",
      "Epoch 1/75\n",
      "1/1 [==============================] - 1s 826ms/step - loss: 0.6931 - accuracy: 0.6393\n",
      "Epoch 2/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.7164\n",
      "Epoch 3/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.7164\n",
      "Epoch 4/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6922 - accuracy: 0.7164\n",
      "Epoch 5/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6919 - accuracy: 0.7164\n",
      "Epoch 6/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6916 - accuracy: 0.7164\n",
      "Epoch 7/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6913 - accuracy: 0.7164\n",
      "Epoch 8/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.7164\n",
      "Epoch 9/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6906 - accuracy: 0.7164\n",
      "Epoch 10/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6902 - accuracy: 0.7164\n",
      "Epoch 11/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6899 - accuracy: 0.7164\n",
      "Epoch 12/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6894 - accuracy: 0.7164\n",
      "Epoch 13/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6890 - accuracy: 0.7164\n",
      "Epoch 14/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6887 - accuracy: 0.7164\n",
      "Epoch 15/75\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.7164\n",
      "Epoch 16/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6877 - accuracy: 0.7164\n",
      "Epoch 17/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6873 - accuracy: 0.7164\n",
      "Epoch 18/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6868 - accuracy: 0.7164\n",
      "Epoch 19/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6862 - accuracy: 0.7164\n",
      "Epoch 20/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.7164\n",
      "Epoch 21/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6851 - accuracy: 0.7164\n",
      "Epoch 22/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6846 - accuracy: 0.7164\n",
      "Epoch 23/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6837 - accuracy: 0.7164\n",
      "Epoch 24/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6832 - accuracy: 0.7164\n",
      "Epoch 25/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6824 - accuracy: 0.7164\n",
      "Epoch 26/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6814 - accuracy: 0.7164\n",
      "Epoch 27/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6808 - accuracy: 0.7164\n",
      "Epoch 28/75\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6798 - accuracy: 0.7164\n",
      "Epoch 29/75\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6783 - accuracy: 0.7164\n",
      "Epoch 30/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6773 - accuracy: 0.7164\n",
      "Epoch 31/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6758 - accuracy: 0.7164\n",
      "Epoch 32/75\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6746 - accuracy: 0.7164\n",
      "Epoch 33/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6734 - accuracy: 0.7164\n",
      "Epoch 34/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6718 - accuracy: 0.7164\n",
      "Epoch 35/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6703 - accuracy: 0.7164\n",
      "Epoch 36/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6681 - accuracy: 0.7164\n",
      "Epoch 37/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6657 - accuracy: 0.7164\n",
      "Epoch 38/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6638 - accuracy: 0.7164\n",
      "Epoch 39/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6609 - accuracy: 0.7164\n",
      "Epoch 40/75\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.7164\n",
      "Epoch 41/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6556 - accuracy: 0.7164\n",
      "Epoch 42/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6524 - accuracy: 0.7164\n",
      "Epoch 43/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6464 - accuracy: 0.7164\n",
      "Epoch 44/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6451 - accuracy: 0.7164\n",
      "Epoch 45/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.7164\n",
      "Epoch 46/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6361 - accuracy: 0.7164\n",
      "Epoch 47/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6295 - accuracy: 0.7164\n",
      "Epoch 48/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6285 - accuracy: 0.7164\n",
      "Epoch 49/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6195 - accuracy: 0.7164\n",
      "Epoch 50/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6132 - accuracy: 0.7164\n",
      "Epoch 51/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6066 - accuracy: 0.7164\n",
      "Epoch 52/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6018 - accuracy: 0.7164\n",
      "Epoch 53/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5958 - accuracy: 0.7164\n",
      "Epoch 54/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5886 - accuracy: 0.7164\n",
      "Epoch 55/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5833 - accuracy: 0.7164\n",
      "Epoch 56/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5702 - accuracy: 0.7164\n",
      "Epoch 57/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5696 - accuracy: 0.7164\n",
      "Epoch 58/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5598 - accuracy: 0.7164\n",
      "Epoch 59/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5493 - accuracy: 0.7164\n",
      "Epoch 60/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5447 - accuracy: 0.7164\n",
      "Epoch 61/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.7164\n",
      "Epoch 62/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5278 - accuracy: 0.7164\n",
      "Epoch 63/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7164\n",
      "Epoch 64/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.7164\n",
      "Epoch 65/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5177 - accuracy: 0.7164\n",
      "Epoch 66/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.7164\n",
      "Epoch 67/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5153 - accuracy: 0.7164\n",
      "Epoch 68/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5005 - accuracy: 0.7164\n",
      "Epoch 69/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5209 - accuracy: 0.7164\n",
      "Epoch 70/75\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5223 - accuracy: 0.7164\n",
      "Epoch 71/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5054 - accuracy: 0.7164\n",
      "Epoch 72/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5109 - accuracy: 0.7164\n",
      "Epoch 73/75\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5029 - accuracy: 0.7164\n",
      "Epoch 74/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7164\n",
      "Epoch 75/75\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5040 - accuracy: 0.7164\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "can't pickle weakref objects",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-f4d1f7b00100>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m# with open(\"./Models/DL_model_{}PC_SL{}_TP{}_btc.pkl\".format(nPCs, stoploss, takeprofit), 'wb') as f:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m#     pk.dump(classifier, f)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mpk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./Models/DL_model_{}PC_SL{}_TP{}_btc.pkl\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnPCs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstoploss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeprofit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: can't pickle weakref objects"
     ]
    }
   ],
   "source": [
    "for nPCs in list_nPCs:\n",
    "    print(nPCs)\n",
    "    X = trainset_final.iloc[:, :nPCs]\n",
    "    y = trainset[\"result\"]\n",
    "\n",
    "    # Build model and train it\n",
    "    classifier = Sequential()\n",
    "\n",
    "    dropout_fraction = 0.2\n",
    "\n",
    "    #First Hidden Layer\n",
    "    classifier.add(Dense(32, activation='relu', kernel_initializer='random_normal', input_dim=nPCs))\n",
    "    classifier.add(Dropout(dropout_fraction))\n",
    "\n",
    "    #Second, third and fourth  hidden Layers\n",
    "    classifier.add(Dense(32, activation='relu', kernel_initializer='random_normal'))\n",
    "    classifier.add(Dropout(dropout_fraction))\n",
    "\n",
    "    classifier.add(Dense(16, activation='relu', kernel_initializer='random_normal'))\n",
    "    classifier.add(Dropout(dropout_fraction))\n",
    "\n",
    "    classifier.add(Dense(16, activation='relu', kernel_initializer='random_normal'))\n",
    "    classifier.add(Dropout(dropout_fraction))\n",
    "\n",
    "    #Output Layer\n",
    "    classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "    #Compiling the neural network\n",
    "    classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "    #Fitting the data to the training dataset\n",
    "    classifier.fit(X,y, batch_size=500, epochs=75, verbose =1)\n",
    "\n",
    "    pk.dump(classifier, open(\"./Models/DL_model_{}PC_SL{}_TP{}_btc.pkl\".format(nPCs, stoploss, takeprofit), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 32)                352       \n_________________________________________________________________\ndropout (Dropout)            (None, 32)                0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 32)                1056      \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 32)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 16)                528       \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 16)                0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 16)                272       \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 16)                0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 1)                 17        \n=================================================================\nTotal params: 2,225\nTrainable params: 2,225\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # (b) Build and train several models different amounts of PCs\n",
    "# for nPCs in list_nPCs:\n",
    "#     print(nPCs)\n",
    "#     X = trainset_final.iloc[:, :nPCs]\n",
    "#     y = trainset[\"result\"]\n",
    "\n",
    "#     # Build model and train it\n",
    "#     classifier = Sequential()\n",
    "#     #First Hidden Layer\n",
    "#     classifier.add(Dense(32, activation='relu', kernel_initializer='random_normal', input_dim=nPCs))\n",
    "#     #Second, third and fourth  hidden Layers\n",
    "#     classifier.add(Dense(32, activation='relu', kernel_initializer='random_normal'))\n",
    "#     classifier.add(Dense(16, activation='relu', kernel_initializer='random_normal'))\n",
    "#     classifier.add(Dense(16, activation='relu', kernel_initializer='random_normal'))\n",
    "\n",
    "#     #Output Layer\n",
    "#     classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "#     #Compiling the neural network\n",
    "#     classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "#     #Fitting the data to the training dataset\n",
    "#     classifier.fit(X,y, batch_size=500, epochs=75, verbose =1)\n",
    "\n",
    "#     # with open(\"./Models/DL_model_{}PC_SL{}_TP{}_btc.pkl\".format(nPCs, stoploss, takeprofit), 'wb') as f:\n",
    "#     #     pk.dump(classifier, f)\n",
    "#     pk.dump(classifier, open(\"./Models/DL_model_{}PC_SL{}_TP{}_btc.pkl\".format(nPCs, stoploss, takeprofit), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies, nPCs_list = [], []\n",
    "for nPCs in list_nPCs:\n",
    "    print(nPCs)\n",
    "    with open(\"./Models/DL_model_{}PC_SL{}_TP{}_btc.pkl\".format(nPCs, stoploss, takeprofit), 'rb') as f:\n",
    "        clf = pk.load(f)\n",
    "    # Compute predictions on testset\n",
    "    preds = (clf.predict(validation_set_final.iloc[:, :nPCs]) > 0.5)*1\n",
    "\n",
    "    # Assess accuracy on Bullish predictions only (because we will only perform Bullish trades IRL) : we prioritize selectivity\n",
    "    validation_set1 = validation_set[preds == 1].copy()\n",
    "    accuracies.append(np.mean(preds == list(validation_set1['result'])))\n",
    "    nPCs_list.append(nPCs)\n",
    "\n",
    "recap = pd.DataFrame({'nPCs' : list(nPCs_list), 'Accuracy' : (list(accuracies))})\n",
    "recap.to_csv('./Results/Comparative_All_models_SL{}_TP{}_btc.csv'.format(stoploss, takeprofit), index = False)\n",
    "print(recap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}